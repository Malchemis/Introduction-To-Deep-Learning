{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Contrastive Learning using FAISS and PyTorch on CIFAR-10 dataset",
   "id": "94e6f16a180056fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:43:47.270480Z",
     "start_time": "2024-12-06T10:43:42.962339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "import faiss\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, pretrained=False):\n",
    "        super().__init__()\n",
    "        backbone = resnet18(pretrained=pretrained)\n",
    "        # Remove the original FC layer\n",
    "        self.features = nn.Sequential(*list(backbone.children())[:-1]) \n",
    "        # Add a new FC layer for embedding\n",
    "        self.fc = nn.Linear(backbone.fc.in_features, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x -> features\n",
    "        feats = self.features(x)  # shape: Bx512x1x1 for resnet18\n",
    "        feats = feats.view(feats.size(0), -1)\n",
    "        embedding = self.fc(feats)\n",
    "        return embedding, feats  # Return both the embedding and the last conv features\n",
    "\n",
    "\n",
    "class SimpleEncoderModel(pl.LightningModule):\n",
    "    def __init__(self, embedding_dim=128, num_classes=10, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(embedding_dim=embedding_dim, pretrained=False)\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding, _ = self.encoder(x)\n",
    "        return self.classifier(embedding)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log('pretrain_loss', loss, prog_bar=True)\n",
    "        self.log('pretrain_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\n",
    "class PretrainDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, pretrain_percentage=0.2, data_dir='../data/raw'):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.pretrain_percentage = pretrain_percentage\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets.CIFAR10(root=self.data_dir, train=True, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        cifar_full = datasets.CIFAR10(root=self.data_dir, train=True, transform=transform)\n",
    "        total_train = len(cifar_full)\n",
    "        pretrain_size = int(self.pretrain_percentage * total_train)\n",
    "        self.pretrain_data, _ = random_split(cifar_full, [pretrain_size, total_train - pretrain_size],\n",
    "                                             generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.pretrain_data, batch_size=self.batch_size, shuffle=True)"
   ],
   "id": "6a4d050ebcd1c305",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:49:10.703852Z",
     "start_time": "2024-12-06T10:44:26.841213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pretrain encoder\n",
    "pretrain_dm = PretrainDataModule()\n",
    "pretrain_model = SimpleEncoderModel(embedding_dim=128, num_classes=10, lr=1e-3)\n",
    "trainer_pretrain = pl.Trainer(max_epochs=15, accelerator='gpu', devices=1, default_root_dir='../models/contrastive_learning')\n",
    "trainer_pretrain.fit(pretrain_model, pretrain_dm)\n",
    "torch.save(pretrain_model.encoder.state_dict(), \"../models/pretrained_encoder.pth\")\n"
   ],
   "id": "2db6b6e1f0a81142",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type    | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | encoder    | Encoder | 11.2 M | train\n",
      "1 | classifier | Linear  | 1.3 K  | train\n",
      "-----------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.974    Total estimated model params size (MB)\n",
      "70        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 313/313 [00:18<00:00, 16.96it/s, v_num=14, pretrain_loss=0.385, pretrain_acc=0.938] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 313/313 [00:19<00:00, 16.45it/s, v_num=14, pretrain_loss=0.385, pretrain_acc=0.938]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:54:22.177177Z",
     "start_time": "2024-12-06T10:54:22.159970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RelativeLearningModel(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 embedding_dim=128, \n",
    "                 k=5, \n",
    "                 num_classes=10, \n",
    "                 batch_size=32, \n",
    "                 freeze_encoder=True, \n",
    "                 lr=1e-3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Load the same encoder definition\n",
    "        self.encoder = Encoder(embedding_dim=embedding_dim, pretrained=False)\n",
    "        self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.index = faiss.IndexFlatL2(embedding_dim)\n",
    "        \n",
    "        # Suppose we merge:\n",
    "        # - The embedding (128 dim)\n",
    "        # - Mean neighbor embedding (128 dim)\n",
    "        # - Neighbor label distribution (k * num_classes)\n",
    "        # - Possibly distances: (k)\n",
    "        # Decide what features we use. For simplicity:\n",
    "        # Combined input: embedding (128) + mean neighbor embedding (128) + neighbor label counts (num_classes) + distances summary (like mean distance)\n",
    "        decision_input_dim = 128 + 128 + num_classes + 1  # Example setup\n",
    "        self.decision_head = nn.Sequential(\n",
    "            nn.Linear(decision_input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def load_pretrained_encoder(self, path):\n",
    "        state_dict = torch.load(path, map_location=self.device, weights_only=True)\n",
    "        self.encoder.load_state_dict(state_dict)\n",
    "        if self.hparams.freeze_encoder:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def build_faiss_index(self, dataloader):\n",
    "        self.index.reset()\n",
    "        self.gallery_embeddings = []\n",
    "        self.gallery_labels = []\n",
    "        \n",
    "        self.encoder.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x_faiss, y_faiss) in dataloader:\n",
    "                x_faiss = x_faiss.to(self.device)\n",
    "                emb, _ = self.encoder(x_faiss)\n",
    "                emb = emb.cpu()\n",
    "                self.gallery_embeddings.append(emb)\n",
    "                self.gallery_labels.append(y_faiss)\n",
    "\n",
    "        self.gallery_embeddings = torch.cat(self.gallery_embeddings, dim=0)\n",
    "        self.gallery_labels = torch.cat(self.gallery_labels, dim=0)\n",
    "        self.index.add(self.gallery_embeddings.numpy())\n",
    "        self.encoder.train(mode=not self.hparams.freeze_encoder)\n",
    "\n",
    "    def on_train_start(self):\n",
    "        # Build FAISS index from faiss_data in datamodule\n",
    "        faiss_loader = DataLoader(\n",
    "            self.trainer.datamodule.faiss_data,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        self.build_faiss_index(faiss_loader)\n",
    "\n",
    "    def get_neighbor_features(self, embeddings):\n",
    "        # embeddings: BxD\n",
    "        distances, indices = self.index.search(embeddings.detach().cpu().numpy(), self.k)\n",
    "        neighbor_labels = self.gallery_labels[indices]  # BxK\n",
    "        neighbor_embs = self.gallery_embeddings[indices]  # BxKxD\n",
    "\n",
    "        # Convert to torch\n",
    "        distances = torch.tensor(distances, device=self.device, dtype=torch.float32)\n",
    "\n",
    "        # Aggregate neighbor info\n",
    "        mean_neighbor_emb = neighbor_embs.mean(dim=1).to(self.device)   # BxD\n",
    "        label_counts = torch.zeros(embeddings.size(0), self.num_classes, device=self.device)\n",
    "        for cls in range(self.num_classes):\n",
    "            label_counts[:, cls] = (neighbor_labels == cls).sum(dim=1)\n",
    "\n",
    "        # Distances: we can take mean distance\n",
    "        mean_dist = distances.mean(dim=1, keepdim=True)  # Bx1\n",
    "\n",
    "        return mean_neighbor_emb, label_counts, mean_dist\n",
    "\n",
    "    def shared_step(self, batch):\n",
    "        x, y = batch\n",
    "        embeddings, _ = self.encoder(x)  # embeddings: BxD\n",
    "        mean_neighbor_emb, label_counts, mean_dist = self.get_neighbor_features(embeddings)\n",
    "\n",
    "        # Concatenate features: embeddings + mean_neighbor_emb + label_counts + mean_dist\n",
    "        combined_features = torch.cat([embeddings, mean_neighbor_emb, label_counts, mean_dist], dim=-1)\n",
    "        logits = self.decision_head(combined_features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.shared_step(batch)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if self.index.ntotal == 0:\n",
    "            return\n",
    "        loss, acc = self.shared_step(batch)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        if self.index.ntotal == 0:\n",
    "            return\n",
    "        loss, acc = self.shared_step(batch)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\n",
    "class CIFAR10FaissDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, faiss_percentage=0.1, val_percentage=0.1, data_dir='../data/raw'):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.faiss_percentage = faiss_percentage\n",
    "        self.val_percentage = val_percentage\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def prepare_data(self):\n",
    "        datasets.CIFAR10(root=self.data_dir, train=True, download=True)\n",
    "        datasets.CIFAR10(root=self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        cifar_full = datasets.CIFAR10(root=self.data_dir, train=True, transform=transform)\n",
    "        total_train = len(cifar_full)\n",
    "        faiss_size = int(self.faiss_percentage * total_train)\n",
    "        remain = total_train - faiss_size\n",
    "        self.faiss_data, remain_data = random_split(cifar_full, [faiss_size, remain],\n",
    "                                                    generator=torch.Generator().manual_seed(42))\n",
    "        val_size = int(self.val_percentage * remain)\n",
    "        train_size = remain - val_size\n",
    "        self.train_data, self.val_data = random_split(remain_data, [train_size, val_size],\n",
    "                                                      generator=torch.Generator().manual_seed(42))\n",
    "        self.test_data = datasets.CIFAR10(root=self.data_dir, train=False, transform=transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size)"
   ],
   "id": "262fa4e570e8ac29",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T10:57:43.924513Z",
     "start_time": "2024-12-06T10:54:22.468422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "main_dm = CIFAR10FaissDataModule(faiss_percentage=0.1, val_percentage=0.1)\n",
    "model = RelativeLearningModel(freeze_encoder=False)\n",
    "model.load_pretrained_encoder(\"../models/pretrained_encoder.pth\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=15, callbacks=[early_stopping], accelerator='gpu', devices=1, default_root_dir='../models/contrastive_learning')\n",
    "trainer.fit(model, main_dm)\n",
    "trainer.test(model, datamodule=main_dm)"
   ],
   "id": "3dbc83ddf34759ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type       | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | encoder       | Encoder    | 11.2 M | train\n",
      "1 | decision_head | Sequential | 71.2 K | train\n",
      "-----------------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.253    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1266/1266 [01:24<00:00, 15.01it/s, v_num=18, train_acc=0.300] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   1%|          | 1/141 [00:00<00:02, 50.62it/s]\u001B[A\n",
      "Validation DataLoader 0:   1%|▏         | 2/141 [00:00<00:02, 47.14it/s]\u001B[A\n",
      "Validation DataLoader 0:   2%|▏         | 3/141 [00:00<00:03, 45.71it/s]\u001B[A\n",
      "Validation DataLoader 0:   3%|▎         | 4/141 [00:00<00:03, 44.51it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▎         | 5/141 [00:00<00:03, 44.20it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 6/141 [00:00<00:03, 43.99it/s]\u001B[A\n",
      "Validation DataLoader 0:   5%|▍         | 7/141 [00:00<00:03, 43.79it/s]\u001B[A\n",
      "Validation DataLoader 0:   6%|▌         | 8/141 [00:00<00:03, 43.65it/s]\u001B[A\n",
      "Validation DataLoader 0:   6%|▋         | 9/141 [00:00<00:03, 43.50it/s]\u001B[A\n",
      "Validation DataLoader 0:   7%|▋         | 10/141 [00:00<00:03, 43.40it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 11/141 [00:00<00:03, 43.32it/s]\u001B[A\n",
      "Validation DataLoader 0:   9%|▊         | 12/141 [00:00<00:03, 42.81it/s]\u001B[A\n",
      "Validation DataLoader 0:   9%|▉         | 13/141 [00:00<00:02, 42.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  10%|▉         | 14/141 [00:00<00:02, 42.82it/s]\u001B[A\n",
      "Validation DataLoader 0:  11%|█         | 15/141 [00:00<00:02, 42.82it/s]\u001B[A\n",
      "Validation DataLoader 0:  11%|█▏        | 16/141 [00:00<00:02, 42.80it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 17/141 [00:00<00:02, 42.74it/s]\u001B[A\n",
      "Validation DataLoader 0:  13%|█▎        | 18/141 [00:00<00:02, 42.79it/s]\u001B[A\n",
      "Validation DataLoader 0:  13%|█▎        | 19/141 [00:00<00:02, 42.82it/s]\u001B[A\n",
      "Validation DataLoader 0:  14%|█▍        | 20/141 [00:00<00:02, 42.88it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▍        | 21/141 [00:00<00:02, 42.67it/s]\u001B[A\n",
      "Validation DataLoader 0:  16%|█▌        | 22/141 [00:00<00:02, 42.54it/s]\u001B[A\n",
      "Validation DataLoader 0:  16%|█▋        | 23/141 [00:00<00:02, 42.59it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 24/141 [00:00<00:02, 42.50it/s]\u001B[A\n",
      "Validation DataLoader 0:  18%|█▊        | 25/141 [00:00<00:02, 42.57it/s]\u001B[A\n",
      "Validation DataLoader 0:  18%|█▊        | 26/141 [00:00<00:02, 42.65it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 27/141 [00:00<00:02, 42.75it/s]\u001B[A\n",
      "Validation DataLoader 0:  20%|█▉        | 28/141 [00:00<00:02, 42.86it/s]\u001B[A\n",
      "Validation DataLoader 0:  21%|██        | 29/141 [00:00<00:02, 42.86it/s]\u001B[A\n",
      "Validation DataLoader 0:  21%|██▏       | 30/141 [00:00<00:02, 42.90it/s]\u001B[A\n",
      "Validation DataLoader 0:  22%|██▏       | 31/141 [00:00<00:02, 42.95it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 32/141 [00:00<00:02, 42.98it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 33/141 [00:00<00:02, 43.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  24%|██▍       | 34/141 [00:00<00:02, 43.05it/s]\u001B[A\n",
      "Validation DataLoader 0:  25%|██▍       | 35/141 [00:00<00:02, 43.07it/s]\u001B[A\n",
      "Validation DataLoader 0:  26%|██▌       | 36/141 [00:00<00:02, 43.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  26%|██▌       | 37/141 [00:00<00:02, 43.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 38/141 [00:00<00:02, 43.00it/s]\u001B[A\n",
      "Validation DataLoader 0:  28%|██▊       | 39/141 [00:00<00:02, 42.98it/s]\u001B[A\n",
      "Validation DataLoader 0:  28%|██▊       | 40/141 [00:00<00:02, 42.94it/s]\u001B[A\n",
      "Validation DataLoader 0:  29%|██▉       | 41/141 [00:00<00:02, 42.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  30%|██▉       | 42/141 [00:00<00:02, 42.93it/s]\u001B[A\n",
      "Validation DataLoader 0:  30%|███       | 43/141 [00:01<00:02, 42.91it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 44/141 [00:01<00:02, 42.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  32%|███▏      | 45/141 [00:01<00:02, 42.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 46/141 [00:01<00:02, 42.90it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 47/141 [00:01<00:02, 42.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  34%|███▍      | 48/141 [00:01<00:02, 42.84it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 49/141 [00:01<00:02, 42.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▌      | 50/141 [00:01<00:02, 42.75it/s]\u001B[A\n",
      "Validation DataLoader 0:  36%|███▌      | 51/141 [00:01<00:02, 42.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  37%|███▋      | 52/141 [00:01<00:02, 42.72it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 53/141 [00:01<00:02, 42.77it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 54/141 [00:01<00:02, 42.73it/s]\u001B[A\n",
      "Validation DataLoader 0:  39%|███▉      | 55/141 [00:01<00:02, 42.74it/s]\u001B[A\n",
      "Validation DataLoader 0:  40%|███▉      | 56/141 [00:01<00:01, 42.78it/s]\u001B[A\n",
      "Validation DataLoader 0:  40%|████      | 57/141 [00:01<00:01, 42.80it/s]\u001B[A\n",
      "Validation DataLoader 0:  41%|████      | 58/141 [00:01<00:01, 42.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 59/141 [00:01<00:01, 42.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  43%|████▎     | 60/141 [00:01<00:01, 42.93it/s]\u001B[A\n",
      "Validation DataLoader 0:  43%|████▎     | 61/141 [00:01<00:01, 42.96it/s]\u001B[A\n",
      "Validation DataLoader 0:  44%|████▍     | 62/141 [00:01<00:01, 42.96it/s]\u001B[A\n",
      "Validation DataLoader 0:  45%|████▍     | 63/141 [00:01<00:01, 42.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  45%|████▌     | 64/141 [00:01<00:01, 42.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 65/141 [00:01<00:01, 42.79it/s]\u001B[A\n",
      "Validation DataLoader 0:  47%|████▋     | 66/141 [00:01<00:01, 42.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  48%|████▊     | 67/141 [00:01<00:01, 42.67it/s]\u001B[A\n",
      "Validation DataLoader 0:  48%|████▊     | 68/141 [00:01<00:01, 42.68it/s]\u001B[A\n",
      "Validation DataLoader 0:  49%|████▉     | 69/141 [00:01<00:01, 42.66it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|████▉     | 70/141 [00:01<00:01, 42.53it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 71/141 [00:01<00:01, 42.50it/s]\u001B[A\n",
      "Validation DataLoader 0:  51%|█████     | 72/141 [00:01<00:01, 42.45it/s]\u001B[A\n",
      "Validation DataLoader 0:  52%|█████▏    | 73/141 [00:01<00:01, 42.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  52%|█████▏    | 74/141 [00:01<00:01, 42.24it/s]\u001B[A\n",
      "Validation DataLoader 0:  53%|█████▎    | 75/141 [00:01<00:01, 42.19it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 76/141 [00:01<00:01, 42.21it/s]\u001B[A\n",
      "Validation DataLoader 0:  55%|█████▍    | 77/141 [00:01<00:01, 42.20it/s]\u001B[A\n",
      "Validation DataLoader 0:  55%|█████▌    | 78/141 [00:01<00:01, 42.16it/s]\u001B[A\n",
      "Validation DataLoader 0:  56%|█████▌    | 79/141 [00:01<00:01, 42.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  57%|█████▋    | 80/141 [00:01<00:01, 42.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  57%|█████▋    | 81/141 [00:01<00:01, 42.13it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 82/141 [00:01<00:01, 42.13it/s]\u001B[A\n",
      "Validation DataLoader 0:  59%|█████▉    | 83/141 [00:01<00:01, 42.14it/s]\u001B[A\n",
      "Validation DataLoader 0:  60%|█████▉    | 84/141 [00:01<00:01, 42.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  60%|██████    | 85/141 [00:02<00:01, 42.03it/s]\u001B[A\n",
      "Validation DataLoader 0:  61%|██████    | 86/141 [00:02<00:01, 41.96it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 87/141 [00:02<00:01, 41.86it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 88/141 [00:02<00:01, 41.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  63%|██████▎   | 89/141 [00:02<00:01, 41.82it/s]\u001B[A\n",
      "Validation DataLoader 0:  64%|██████▍   | 90/141 [00:02<00:01, 41.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▍   | 91/141 [00:02<00:01, 41.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 92/141 [00:02<00:01, 41.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 93/141 [00:02<00:01, 41.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 94/141 [00:02<00:01, 41.73it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 95/141 [00:02<00:01, 41.73it/s]\u001B[A\n",
      "Validation DataLoader 0:  68%|██████▊   | 96/141 [00:02<00:01, 41.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 97/141 [00:02<00:01, 41.73it/s]\u001B[A\n",
      "Validation DataLoader 0:  70%|██████▉   | 98/141 [00:02<00:01, 41.72it/s]\u001B[A\n",
      "Validation DataLoader 0:  70%|███████   | 99/141 [00:02<00:01, 41.74it/s]\u001B[A\n",
      "Validation DataLoader 0:  71%|███████   | 100/141 [00:02<00:00, 41.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 101/141 [00:02<00:00, 41.77it/s]\u001B[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 102/141 [00:02<00:00, 41.78it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 103/141 [00:02<00:00, 41.79it/s]\u001B[A\n",
      "Validation DataLoader 0:  74%|███████▍  | 104/141 [00:02<00:00, 41.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  74%|███████▍  | 105/141 [00:02<00:00, 41.84it/s]\u001B[A\n",
      "Validation DataLoader 0:  75%|███████▌  | 106/141 [00:02<00:00, 41.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 107/141 [00:02<00:00, 41.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 108/141 [00:02<00:00, 41.86it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 109/141 [00:02<00:00, 41.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  78%|███████▊  | 110/141 [00:02<00:00, 41.88it/s]\u001B[A\n",
      "Validation DataLoader 0:  79%|███████▊  | 111/141 [00:02<00:00, 41.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  79%|███████▉  | 112/141 [00:02<00:00, 41.83it/s]\u001B[A\n",
      "Validation DataLoader 0:  80%|████████  | 113/141 [00:02<00:00, 41.85it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 114/141 [00:02<00:00, 41.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  82%|████████▏ | 115/141 [00:02<00:00, 41.89it/s]\u001B[A\n",
      "Validation DataLoader 0:  82%|████████▏ | 116/141 [00:02<00:00, 41.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 117/141 [00:02<00:00, 41.94it/s]\u001B[A\n",
      "Validation DataLoader 0:  84%|████████▎ | 118/141 [00:02<00:00, 41.94it/s]\u001B[A\n",
      "Validation DataLoader 0:  84%|████████▍ | 119/141 [00:02<00:00, 41.95it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 120/141 [00:02<00:00, 41.97it/s]\u001B[A\n",
      "Validation DataLoader 0:  86%|████████▌ | 121/141 [00:02<00:00, 42.00it/s]\u001B[A\n",
      "Validation DataLoader 0:  87%|████████▋ | 122/141 [00:02<00:00, 42.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  87%|████████▋ | 123/141 [00:02<00:00, 42.06it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 124/141 [00:02<00:00, 42.09it/s]\u001B[A\n",
      "Validation DataLoader 0:  89%|████████▊ | 125/141 [00:02<00:00, 42.13it/s]\u001B[A\n",
      "Validation DataLoader 0:  89%|████████▉ | 126/141 [00:02<00:00, 42.15it/s]\u001B[A\n",
      "Validation DataLoader 0:  90%|█████████ | 127/141 [00:03<00:00, 42.19it/s]\u001B[A\n",
      "Validation DataLoader 0:  91%|█████████ | 128/141 [00:03<00:00, 42.21it/s]\u001B[A\n",
      "Validation DataLoader 0:  91%|█████████▏| 129/141 [00:03<00:00, 42.23it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 130/141 [00:03<00:00, 42.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  93%|█████████▎| 131/141 [00:03<00:00, 42.26it/s]\u001B[A\n",
      "Validation DataLoader 0:  94%|█████████▎| 132/141 [00:03<00:00, 42.27it/s]\u001B[A\n",
      "Validation DataLoader 0:  94%|█████████▍| 133/141 [00:03<00:00, 42.29it/s]\u001B[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 134/141 [00:03<00:00, 42.29it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 135/141 [00:03<00:00, 42.31it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▋| 136/141 [00:03<00:00, 42.34it/s]\u001B[A\n",
      "Validation DataLoader 0:  97%|█████████▋| 137/141 [00:03<00:00, 42.35it/s]\u001B[A\n",
      "Validation DataLoader 0:  98%|█████████▊| 138/141 [00:03<00:00, 42.37it/s]\u001B[A\n",
      "Validation DataLoader 0:  99%|█████████▊| 139/141 [00:03<00:00, 42.37it/s]\u001B[A\n",
      "Validation DataLoader 0:  99%|█████████▉| 140/141 [00:03<00:00, 42.39it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 141/141 [00:03<00:00, 42.45it/s]\u001B[A\n",
      "Epoch 0: 100%|██████████| 1266/1266 [01:27<00:00, 14.44it/s, v_num=18, train_acc=0.300, val_loss=2.060, val_acc=0.232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1266/1266 [01:23<00:00, 15.15it/s, v_num=18, train_acc=0.200, val_loss=2.060, val_acc=0.232] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/141 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   1%|          | 1/141 [00:00<00:03, 45.78it/s]\u001B[A\n",
      "Validation DataLoader 0:   1%|▏         | 2/141 [00:00<00:03, 42.82it/s]\u001B[A\n",
      "Validation DataLoader 0:   2%|▏         | 3/141 [00:00<00:03, 42.91it/s]\u001B[A\n",
      "Validation DataLoader 0:   3%|▎         | 4/141 [00:00<00:03, 43.00it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▎         | 5/141 [00:00<00:03, 43.61it/s]\u001B[A\n",
      "Validation DataLoader 0:   4%|▍         | 6/141 [00:00<00:03, 43.87it/s]\u001B[A\n",
      "Validation DataLoader 0:   5%|▍         | 7/141 [00:00<00:03, 44.16it/s]\u001B[A\n",
      "Validation DataLoader 0:   6%|▌         | 8/141 [00:00<00:02, 44.41it/s]\u001B[A\n",
      "Validation DataLoader 0:   6%|▋         | 9/141 [00:00<00:02, 44.63it/s]\u001B[A\n",
      "Validation DataLoader 0:   7%|▋         | 10/141 [00:00<00:02, 44.78it/s]\u001B[A\n",
      "Validation DataLoader 0:   8%|▊         | 11/141 [00:00<00:02, 44.95it/s]\u001B[A\n",
      "Validation DataLoader 0:   9%|▊         | 12/141 [00:00<00:02, 45.01it/s]\u001B[A\n",
      "Validation DataLoader 0:   9%|▉         | 13/141 [00:00<00:02, 45.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  10%|▉         | 14/141 [00:00<00:02, 45.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  11%|█         | 15/141 [00:00<00:02, 45.01it/s]\u001B[A\n",
      "Validation DataLoader 0:  11%|█▏        | 16/141 [00:00<00:02, 44.95it/s]\u001B[A\n",
      "Validation DataLoader 0:  12%|█▏        | 17/141 [00:00<00:02, 44.86it/s]\u001B[A\n",
      "Validation DataLoader 0:  13%|█▎        | 18/141 [00:00<00:02, 44.93it/s]\u001B[A\n",
      "Validation DataLoader 0:  13%|█▎        | 19/141 [00:00<00:02, 44.97it/s]\u001B[A\n",
      "Validation DataLoader 0:  14%|█▍        | 20/141 [00:00<00:02, 44.98it/s]\u001B[A\n",
      "Validation DataLoader 0:  15%|█▍        | 21/141 [00:00<00:02, 45.06it/s]\u001B[A\n",
      "Validation DataLoader 0:  16%|█▌        | 22/141 [00:00<00:02, 45.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  16%|█▋        | 23/141 [00:00<00:02, 45.12it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 24/141 [00:00<00:02, 45.16it/s]\u001B[A\n",
      "Validation DataLoader 0:  18%|█▊        | 25/141 [00:00<00:02, 45.20it/s]\u001B[A\n",
      "Validation DataLoader 0:  18%|█▊        | 26/141 [00:00<00:02, 45.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  19%|█▉        | 27/141 [00:00<00:02, 45.28it/s]\u001B[A\n",
      "Validation DataLoader 0:  20%|█▉        | 28/141 [00:00<00:02, 45.31it/s]\u001B[A\n",
      "Validation DataLoader 0:  21%|██        | 29/141 [00:00<00:02, 45.32it/s]\u001B[A\n",
      "Validation DataLoader 0:  21%|██▏       | 30/141 [00:00<00:02, 45.32it/s]\u001B[A\n",
      "Validation DataLoader 0:  22%|██▏       | 31/141 [00:00<00:02, 45.33it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 32/141 [00:00<00:02, 45.33it/s]\u001B[A\n",
      "Validation DataLoader 0:  23%|██▎       | 33/141 [00:00<00:02, 45.33it/s]\u001B[A\n",
      "Validation DataLoader 0:  24%|██▍       | 34/141 [00:00<00:02, 45.32it/s]\u001B[A\n",
      "Validation DataLoader 0:  25%|██▍       | 35/141 [00:00<00:02, 45.30it/s]\u001B[A\n",
      "Validation DataLoader 0:  26%|██▌       | 36/141 [00:00<00:02, 45.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  26%|██▌       | 37/141 [00:00<00:02, 45.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  27%|██▋       | 38/141 [00:00<00:02, 45.13it/s]\u001B[A\n",
      "Validation DataLoader 0:  28%|██▊       | 39/141 [00:00<00:02, 45.02it/s]\u001B[A\n",
      "Validation DataLoader 0:  28%|██▊       | 40/141 [00:00<00:02, 44.99it/s]\u001B[A\n",
      "Validation DataLoader 0:  29%|██▉       | 41/141 [00:00<00:02, 44.90it/s]\u001B[A\n",
      "Validation DataLoader 0:  30%|██▉       | 42/141 [00:00<00:02, 44.88it/s]\u001B[A\n",
      "Validation DataLoader 0:  30%|███       | 43/141 [00:00<00:02, 44.81it/s]\u001B[A\n",
      "Validation DataLoader 0:  31%|███       | 44/141 [00:00<00:02, 44.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  32%|███▏      | 45/141 [00:01<00:02, 44.73it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 46/141 [00:01<00:02, 44.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 47/141 [00:01<00:02, 44.74it/s]\u001B[A\n",
      "Validation DataLoader 0:  34%|███▍      | 48/141 [00:01<00:02, 44.78it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▍      | 49/141 [00:01<00:02, 44.77it/s]\u001B[A\n",
      "Validation DataLoader 0:  35%|███▌      | 50/141 [00:01<00:02, 44.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  36%|███▌      | 51/141 [00:01<00:02, 44.78it/s]\u001B[A\n",
      "Validation DataLoader 0:  37%|███▋      | 52/141 [00:01<00:01, 44.76it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 53/141 [00:01<00:01, 44.70it/s]\u001B[A\n",
      "Validation DataLoader 0:  38%|███▊      | 54/141 [00:01<00:01, 44.67it/s]\u001B[A\n",
      "Validation DataLoader 0:  39%|███▉      | 55/141 [00:01<00:01, 44.69it/s]\u001B[A\n",
      "Validation DataLoader 0:  40%|███▉      | 56/141 [00:01<00:01, 44.64it/s]\u001B[A\n",
      "Validation DataLoader 0:  40%|████      | 57/141 [00:01<00:01, 44.60it/s]\u001B[A\n",
      "Validation DataLoader 0:  41%|████      | 58/141 [00:01<00:01, 44.55it/s]\u001B[A\n",
      "Validation DataLoader 0:  42%|████▏     | 59/141 [00:01<00:01, 44.52it/s]\u001B[A\n",
      "Validation DataLoader 0:  43%|████▎     | 60/141 [00:01<00:01, 44.51it/s]\u001B[A\n",
      "Validation DataLoader 0:  43%|████▎     | 61/141 [00:01<00:01, 44.49it/s]\u001B[A\n",
      "Validation DataLoader 0:  44%|████▍     | 62/141 [00:01<00:01, 44.45it/s]\u001B[A\n",
      "Validation DataLoader 0:  45%|████▍     | 63/141 [00:01<00:01, 44.41it/s]\u001B[A\n",
      "Validation DataLoader 0:  45%|████▌     | 64/141 [00:01<00:01, 44.38it/s]\u001B[A\n",
      "Validation DataLoader 0:  46%|████▌     | 65/141 [00:01<00:01, 44.33it/s]\u001B[A\n",
      "Validation DataLoader 0:  47%|████▋     | 66/141 [00:01<00:01, 44.29it/s]\u001B[A\n",
      "Validation DataLoader 0:  48%|████▊     | 67/141 [00:01<00:01, 44.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  48%|████▊     | 68/141 [00:01<00:01, 44.24it/s]\u001B[A\n",
      "Validation DataLoader 0:  49%|████▉     | 69/141 [00:01<00:01, 44.21it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|████▉     | 70/141 [00:01<00:01, 44.17it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 71/141 [00:01<00:01, 44.14it/s]\u001B[A\n",
      "Validation DataLoader 0:  51%|█████     | 72/141 [00:01<00:01, 44.07it/s]\u001B[A\n",
      "Validation DataLoader 0:  52%|█████▏    | 73/141 [00:01<00:01, 44.04it/s]\u001B[A\n",
      "Validation DataLoader 0:  52%|█████▏    | 74/141 [00:01<00:01, 43.95it/s]\u001B[A\n",
      "Validation DataLoader 0:  53%|█████▎    | 75/141 [00:01<00:01, 43.92it/s]\u001B[A\n",
      "Validation DataLoader 0:  54%|█████▍    | 76/141 [00:01<00:01, 43.88it/s]\u001B[A\n",
      "Validation DataLoader 0:  55%|█████▍    | 77/141 [00:01<00:01, 43.85it/s]\u001B[A\n",
      "Validation DataLoader 0:  55%|█████▌    | 78/141 [00:01<00:01, 43.82it/s]\u001B[A\n",
      "Validation DataLoader 0:  56%|█████▌    | 79/141 [00:01<00:01, 43.79it/s]\u001B[A\n",
      "Validation DataLoader 0:  57%|█████▋    | 80/141 [00:01<00:01, 43.75it/s]\u001B[A\n",
      "Validation DataLoader 0:  57%|█████▋    | 81/141 [00:01<00:01, 43.72it/s]\u001B[A\n",
      "Validation DataLoader 0:  58%|█████▊    | 82/141 [00:01<00:01, 43.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  59%|█████▉    | 83/141 [00:01<00:01, 43.69it/s]\u001B[A\n",
      "Validation DataLoader 0:  60%|█████▉    | 84/141 [00:01<00:01, 43.68it/s]\u001B[A\n",
      "Validation DataLoader 0:  60%|██████    | 85/141 [00:01<00:01, 43.66it/s]\u001B[A\n",
      "Validation DataLoader 0:  61%|██████    | 86/141 [00:01<00:01, 43.65it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 87/141 [00:01<00:01, 43.64it/s]\u001B[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 88/141 [00:02<00:01, 43.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  63%|██████▎   | 89/141 [00:02<00:01, 43.61it/s]\u001B[A\n",
      "Validation DataLoader 0:  64%|██████▍   | 90/141 [00:02<00:01, 43.60it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▍   | 91/141 [00:02<00:01, 43.58it/s]\u001B[A\n",
      "Validation DataLoader 0:  65%|██████▌   | 92/141 [00:02<00:01, 43.58it/s]\u001B[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 93/141 [00:02<00:01, 43.56it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 94/141 [00:02<00:01, 43.55it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 95/141 [00:02<00:01, 43.46it/s]\u001B[A\n",
      "Validation DataLoader 0:  68%|██████▊   | 96/141 [00:02<00:01, 43.40it/s]\u001B[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 97/141 [00:02<00:01, 43.33it/s]\u001B[A\n",
      "Validation DataLoader 0:  70%|██████▉   | 98/141 [00:02<00:00, 43.25it/s]\u001B[A\n",
      "Validation DataLoader 0:  70%|███████   | 99/141 [00:02<00:00, 43.18it/s]\u001B[A\n",
      "Validation DataLoader 0:  71%|███████   | 100/141 [00:02<00:00, 43.17it/s]\u001B[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 101/141 [00:02<00:00, 43.15it/s]\u001B[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 102/141 [00:02<00:00, 43.15it/s]\u001B[A\n",
      "Validation DataLoader 0:  73%|███████▎  | 103/141 [00:02<00:00, 43.16it/s]\u001B[A\n",
      "Validation DataLoader 0:  74%|███████▍  | 104/141 [00:02<00:00, 43.12it/s]\u001B[A\n",
      "Validation DataLoader 0:  74%|███████▍  | 105/141 [00:02<00:00, 43.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  75%|███████▌  | 106/141 [00:02<00:00, 43.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 107/141 [00:02<00:00, 43.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 108/141 [00:02<00:00, 43.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  77%|███████▋  | 109/141 [00:02<00:00, 43.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  78%|███████▊  | 110/141 [00:02<00:00, 43.09it/s]\u001B[A\n",
      "Validation DataLoader 0:  79%|███████▊  | 111/141 [00:02<00:00, 43.09it/s]\u001B[A\n",
      "Validation DataLoader 0:  79%|███████▉  | 112/141 [00:02<00:00, 43.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  80%|████████  | 113/141 [00:02<00:00, 43.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  81%|████████  | 114/141 [00:02<00:00, 43.11it/s]\u001B[A\n",
      "Validation DataLoader 0:  82%|████████▏ | 115/141 [00:02<00:00, 43.10it/s]\u001B[A\n",
      "Validation DataLoader 0:  82%|████████▏ | 116/141 [00:02<00:00, 43.06it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 117/141 [00:02<00:00, 43.00it/s]\u001B[A\n",
      "Validation DataLoader 0:  84%|████████▎ | 118/141 [00:02<00:00, 42.99it/s]\u001B[A\n",
      "Validation DataLoader 0:  84%|████████▍ | 119/141 [00:02<00:00, 42.96it/s]\u001B[A\n",
      "Validation DataLoader 0:  85%|████████▌ | 120/141 [00:02<00:00, 42.95it/s]\u001B[A\n",
      "Validation DataLoader 0:  86%|████████▌ | 121/141 [00:02<00:00, 42.87it/s]\u001B[A\n",
      "Validation DataLoader 0:  87%|████████▋ | 122/141 [00:02<00:00, 42.84it/s]\u001B[A\n",
      "Validation DataLoader 0:  87%|████████▋ | 123/141 [00:02<00:00, 42.82it/s]\u001B[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 124/141 [00:02<00:00, 42.80it/s]\u001B[A\n",
      "Validation DataLoader 0:  89%|████████▊ | 125/141 [00:02<00:00, 42.75it/s]\u001B[A\n",
      "Validation DataLoader 0:  89%|████████▉ | 126/141 [00:02<00:00, 42.72it/s]\u001B[A\n",
      "Validation DataLoader 0:  90%|█████████ | 127/141 [00:02<00:00, 42.70it/s]\u001B[A\n",
      "Validation DataLoader 0:  91%|█████████ | 128/141 [00:02<00:00, 42.69it/s]\u001B[A\n",
      "Validation DataLoader 0:  91%|█████████▏| 129/141 [00:03<00:00, 42.66it/s]\u001B[A\n",
      "Validation DataLoader 0:  92%|█████████▏| 130/141 [00:03<00:00, 42.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  93%|█████████▎| 131/141 [00:03<00:00, 42.60it/s]\u001B[A\n",
      "Validation DataLoader 0:  94%|█████████▎| 132/141 [00:03<00:00, 42.59it/s]\u001B[A\n",
      "Validation DataLoader 0:  94%|█████████▍| 133/141 [00:03<00:00, 42.59it/s]\u001B[A\n",
      "Validation DataLoader 0:  95%|█████████▌| 134/141 [00:03<00:00, 42.57it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▌| 135/141 [00:03<00:00, 42.55it/s]\u001B[A\n",
      "Validation DataLoader 0:  96%|█████████▋| 136/141 [00:03<00:00, 42.53it/s]\u001B[A\n",
      "Validation DataLoader 0:  97%|█████████▋| 137/141 [00:03<00:00, 42.49it/s]\u001B[A\n",
      "Validation DataLoader 0:  98%|█████████▊| 138/141 [00:03<00:00, 42.46it/s]\u001B[A\n",
      "Validation DataLoader 0:  99%|█████████▊| 139/141 [00:03<00:00, 42.43it/s]\u001B[A\n",
      "Validation DataLoader 0:  99%|█████████▉| 140/141 [00:03<00:00, 42.40it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 141/141 [00:03<00:00, 42.43it/s]\u001B[A\n",
      "Epoch 2:  24%|██▍       | 305/1266 [00:20<01:04, 14.88it/s, v_num=18, train_acc=0.188, val_loss=2.180, val_acc=0.206] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:574\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    568\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    570\u001B[0m     ckpt_path,\n\u001B[1;32m    571\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    572\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    573\u001B[0m )\n\u001B[0;32m--> 574\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run(model, ckpt_path\u001B[38;5;241m=\u001B[39mckpt_path)\n\u001B[1;32m    576\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:981\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    978\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    979\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    980\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 981\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_stage()\n\u001B[1;32m    983\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1025\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start()\n\u001B[0;32m--> 205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance()\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001B[0m, in \u001B[0;36m_FitLoop.advance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 363\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch_loop\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher)\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.run\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madvance(data_fetcher)\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end(data_fetcher)\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:269\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.advance\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    267\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mis_last_batch \u001B[38;5;241m=\u001B[39m data_fetcher\u001B[38;5;241m.\u001B[39mdone\n\u001B[0;32m--> 269\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_callback_hooks(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_train_batch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m, batch_output, batch, batch_idx)\n\u001B[1;32m    270\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_lightning_module_hook(trainer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_train_batch_end\u001B[39m\u001B[38;5;124m\"\u001B[39m, batch_output, batch, batch_idx)\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:218\u001B[0m, in \u001B[0;36m_call_callback_hooks\u001B[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001B[0m\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Callback]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcallback\u001B[38;5;241m.\u001B[39mstate_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 218\u001B[0m             fn(trainer, trainer\u001B[38;5;241m.\u001B[39mlightning_module, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pl_module:\n\u001B[1;32m    221\u001B[0m     \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py:279\u001B[0m, in \u001B[0;36mTQDMProgressBar.on_train_batch_end\u001B[0;34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001B[0m\n\u001B[1;32m    278\u001B[0m _update_n(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_progress_bar, n)\n\u001B[0;32m--> 279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_progress_bar\u001B[38;5;241m.\u001B[39mset_postfix(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_metrics(trainer, pl_module))\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/callbacks/progress/progress_bar.py:198\u001B[0m, in \u001B[0;36mProgressBar.get_metrics\u001B[0;34m(self, trainer, pl_module)\u001B[0m\n\u001B[1;32m    197\u001B[0m standard_metrics \u001B[38;5;241m=\u001B[39m get_standard_metrics(trainer)\n\u001B[0;32m--> 198\u001B[0m pbar_metrics \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mprogress_bar_metrics\n\u001B[1;32m    199\u001B[0m duplicates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(standard_metrics\u001B[38;5;241m.\u001B[39mkeys() \u001B[38;5;241m&\u001B[39m pbar_metrics\u001B[38;5;241m.\u001B[39mkeys())\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1635\u001B[0m, in \u001B[0;36mTrainer.progress_bar_metrics\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1629\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"The metrics sent to the progress bar.\u001B[39;00m\n\u001B[1;32m   1630\u001B[0m \n\u001B[1;32m   1631\u001B[0m \u001B[38;5;124;03mThis includes metrics logged via :meth:`~pytorch_lightning.core.LightningModule.log` with the\u001B[39;00m\n\u001B[1;32m   1632\u001B[0m \u001B[38;5;124;03m:paramref:`~pytorch_lightning.core.LightningModule.log.prog_bar` argument set.\u001B[39;00m\n\u001B[1;32m   1633\u001B[0m \n\u001B[1;32m   1634\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1635\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logger_connector\u001B[38;5;241m.\u001B[39mprogress_bar_metrics\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:253\u001B[0m, in \u001B[0;36m_LoggerConnector.progress_bar_metrics\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_results:\n\u001B[0;32m--> 253\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpbar\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_progress_bar_metrics\u001B[38;5;241m.\u001B[39mupdate(metrics)\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:234\u001B[0m, in \u001B[0;36m_LoggerConnector.metrics\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_results \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_results\u001B[38;5;241m.\u001B[39mmetrics(on_step)\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:490\u001B[0m, in \u001B[0;36m_ResultCollection.metrics\u001B[0;34m(self, on_step)\u001B[0m\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result_metric\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mprog_bar:\n\u001B[0;32m--> 490\u001B[0m         metrics[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpbar\u001B[39m\u001B[38;5;124m\"\u001B[39m][forked_name] \u001B[38;5;241m=\u001B[39m convert_tensors_to_scalars(value)\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m metrics\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/lightning_fabric/utilities/apply_func.py:136\u001B[0m, in \u001B[0;36mconvert_tensors_to_scalars\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m--> 136\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m apply_to_collection(data, Tensor, to_item)\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/lightning_utilities/core/apply_func.py:64\u001B[0m, in \u001B[0;36mapply_to_collection\u001B[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, dtype):  \u001B[38;5;66;03m# single element\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(data, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mlist\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, dtype) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m data):  \u001B[38;5;66;03m# 1d homogeneous list\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/lightning_fabric/utilities/apply_func.py:134\u001B[0m, in \u001B[0;36mconvert_tensors_to_scalars.<locals>.to_item\u001B[0;34m(value)\u001B[0m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe metric `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` does not contain a single element, thus it cannot be converted to a scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    133\u001B[0m     )\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m value\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m model\u001B[38;5;241m.\u001B[39mload_pretrained_encoder(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/pretrained_encoder.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, callbacks\u001B[38;5;241m=\u001B[39m[early_stopping], accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m'\u001B[39m, devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, default_root_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../models/contrastive_learning\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(model, main_dm)\n\u001B[1;32m     16\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtest(model, datamodule\u001B[38;5;241m=\u001B[39mmain_dm)\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:538\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 538\u001B[0m call\u001B[38;5;241m.\u001B[39m_call_and_handle_interrupt(\n\u001B[1;32m    539\u001B[0m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001B[1;32m    540\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/iDL/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:64\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(launcher, _SubprocessScriptLauncher):\n\u001B[1;32m     63\u001B[0m         launcher\u001B[38;5;241m.\u001B[39mkill(_get_sigkill_signal())\n\u001B[0;32m---> 64\u001B[0m     exit(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[1;32m     67\u001B[0m     _interrupt(trainer, exception)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'exit' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56cf5865457c3006"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
